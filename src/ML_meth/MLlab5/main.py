"""Лабораторная работа No5
Реализация алгоритма метода опорных векторов для задачи бинарной
классификации
Цель работы: реализовать метод опорных векторов (SVM) для задачи бинарной
классификации.

https://proproprogs.ru/ml/ml-realizaciya-metoda-opornyh-vektorov-svm
"""


import numpy as np  # 1.23.4
import matplotlib.pyplot as plt  # 3.6.1
from sklearn import svm


#===============================================================================
# Обучающая выборка
#===============================================================================
# вариант 5
data_x = [(5.8, 1.2), (5.6, 1.5), (6.5, 1.5), (6.1, 1.3), (6.4, 1.3), (7.7, 2.0), (6.0, 1.8), (5.6, 1.3), (6.0, 1.6), (5.8, 1.9), (5.7, 2.0), (6.3, 1.5), (6.2, 1.8), (7.7, 2.3), (5.8, 1.2), (6.3, 1.8), (6.0, 1.0), (6.2, 1.3), (5.7, 1.3), (6.3, 1.9), (6.7, 2.5), (5.5, 1.2), (4.9, 1.0), (6.1, 1.4), (6.0, 1.6), (7.2, 2.5), (7.3, 1.8), (6.6, 1.4), (5.6, 2.0), (5.5, 1.0), (6.4, 2.2), (5.6, 1.3), (6.6, 1.3), (6.9, 2.1), (6.8, 2.1), (5.7, 1.3), (7.0, 1.4), (6.1, 1.4), (6.1, 1.8), (6.7, 1.7), (6.0, 1.5), (6.5, 1.8), (6.4, 1.5), (6.9, 1.5), (5.6, 1.3), (6.7, 1.4), (5.8, 1.9), (6.3, 1.3), (6.7, 2.1), (6.2, 2.3), (6.3, 2.4), (6.7, 1.8), (6.4, 2.3), (6.2, 1.5), (6.1, 1.4), (7.1, 2.1), (5.7, 1.0), (6.8, 1.4), (6.8, 2.3), (5.1, 1.1), (4.9, 1.7), (5.9, 1.8), (7.4, 1.9), (6.5, 2.0), (6.7, 1.5), (6.5, 2.0), (5.8, 1.0), (6.4, 2.1), (7.6, 2.1), (5.8, 2.4), (7.7, 2.2), (6.3, 1.5), (5.0, 1.0), (6.3, 1.6), (7.7, 2.3), (6.4, 1.9), (6.5, 2.2), (5.7, 1.2), (6.9, 2.3), (5.7, 1.3), (6.1, 1.2), (5.4, 1.5), (5.2, 1.4), (6.7, 2.3), (7.9, 2.0), (5.6, 1.1), (7.2, 1.8), (5.5, 1.3), (7.2, 1.6), (6.3, 2.5), (6.3, 1.8), (6.7, 2.4), (5.0, 1.0), (6.4, 1.8), (6.9, 2.3), (5.5, 1.3), (5.5, 1.1), (5.9, 1.5), (6.0, 1.5), (5.9, 1.8)]
data_y = [-1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1]
#===============================================================================

clean_data = list(set(zip(data_x, data_y)))  # чистим данные от дублей
classes = {
    'green': {
        'data': np.array([list(data[0]) + [1] for data in clean_data if data[1] == -1]),
        'label': 'Образы 1 класса',
        'alpha': 1,
    },
    'blue': {
        'data': np.array([list(data[0]) + [1] for data in clean_data if data[1] == 1]),
        'label': 'Образы 2 класса',
        'alpha': 1,
    }
}

x_train = np.concatenate((classes['green']['data'], classes['blue']['data']))
y_train = np.concatenate(
    (
        np.full(classes['green']['data'].shape[0], -1),
        np.full(classes['blue']['data'].shape[0], 1)
    )
)
# regularization parameter
clf = svm.SVC(kernel='linear', gamma=0.7, C=1.0)  # SVM с линейным ядром
clf.fit(x_train, y_train)  # нахождение вектора w по обучающей выборке

v = clf.support_vectors_  # выделение опорных векторов
w = clf.coef_[0]
# Перехват (также известный как смещение)
# добавлен в функцию принятия решения. (тета 0)
w0 = clf.intercept_
# координаты разделяющей линии по осям
dividing_line_xx = [np.min(x_train[:, 0]), np.max(x_train[:, 0])]  # относительно оси 0 (х)
dividing_line_yy = np.dot((-1. / w[1]), (np.dot(w[0], dividing_line_xx) + w0))

# print(f"Разделяющая линия = {w}", f"Опорные вектора = {v}", sep='\n')

y_pr = clf.predict(x_train)  # проверка на обучающей выборке
# нули - без ошибок; иначе - ошибка
number_of_errors = x_train.shape[0] - np.count_nonzero((np.array(y_train) - np.array(y_pr)) == 0)  # .count(0)
error_rate = 100 * number_of_errors / x_train.shape[0]

# Построение графиков ----------------------------------------------------------
fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 8))
fig.suptitle(f'SVM\n(вариант №5, размер выборки: {len(clean_data)})', fontsize=16)

for class_i in classes:
    ax.scatter(
        classes[class_i]['data'][:, :1],
        classes[class_i]['data'][:, 1:2],
        color=class_i, label=classes[class_i]['label'],
        alpha=classes[class_i]['alpha'],
    )

ax.scatter(
    v[:, 0], v[:, 1],
    s=150, edgecolor=None,
    alpha=0.5, color='red',
    linewidths=1, marker='+',
    label='Точки опорного вектора'
)

ax.plot(dividing_line_xx, dividing_line_yy, color='orange')

ax.tick_params(labelcolor='indigo')
ax.legend()
ax.set_title(
    'Распределение классификатора: ' +
    f"{number_of_errors} ошибок = " +
    f"{error_rate} %",
    color='black'
)

plt.show()
# ------------------------------------------------------------------------------
